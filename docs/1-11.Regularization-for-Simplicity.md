# 정규화: 단순성

## 플레이그라운드 실습: 과잉교차란?

작업 1: 주어진 모든 교차곱 특성을 사용하여 모델을 그대로 실행합니다. 모델이 데이터 적합성을 갖는 방식에 예외적인 부분이 있나요? 어떤 문제가 있나요?

- 우측 경계가 계속 흔들린다.
- 좌측 상단에 파란색 데이터가 없는데도 파란색 영역이 나타났다가 사라짐
- 선 두께가 두꺼울수록 기여도가 높은 것.
- 이 케이스에서는 교차특성이 선이 더 얇음

작업 2: 다양한 벡터곱 특성을 제거하여 (미미할지라도) 성능을 개선해 보세요. 왜 특성을 제거하면 성능이 개선될까요?

- X1X2, X2^2(또는 X1^2)를 제거하니 경계가 명확해지고, 좌측 상단 파란 부분이 생기지 않는다.
- 교차가 많은 모델은 학습 데이터의 노이즈에 맞추려 하는 특성이 있어, 종종 테스트 데이터에서 모델이 잘 작동하지 않기도 한다.

## 단순성을 위한 정규화: L2 정규화

### 학습 세트와 검증 세트에서의 손실

기존에는 학습 최적화를 말할 때 손실의 최소화 1개만 고려하였는데, 이제는 모델 복잡도를 측정하는 정규화까지 총 2가지를 고려함

모델 복잡도(머신러닝 단기과정에서 다루는)
- 모델의 모든 특성의 가중치(wn)에 대한 함수로서의 모델 복잡도
  + `w1^2 + w2^2 + ...`
  + 이 경우 이상점 가중치가 큰 영향을 끼침(가장 큰 값)
- 0이 아닌 가중치를 사용하는 특성의 총 개수에 대한 함수로서의 모델 복잡도
  + 가중치를 지닌 특성의 총 개수

## 단순성을 위한 정규화: 람다

### 람다(lambda, 정규화율)
- 스칼라값
- 정규화 함수의 상대적 중요도를 지정

#### 손실 방정식
```
Loss = 최소화(손실 함수 + Lambda x 정규화 함수)
```

#### 람다(정규화율)를 높이면
- 과적합이 감소
- 모델의 정확성도 감소
- 정규화 효과가 강화된다 = 가우시안 분포에 가까워 진다

### L2 정규화 수행
#### L2 정규화
- 가중치(w)의 제곱의 합에 비례하여 가중치에 패널티를 주는 정규화
- 가중치(w)를 0에 가깝게 유도하는 데 도움을 준다.
#### L2 정규화를 수행하면
- 가중치 값을 0으로 유도
- 정규분포(가우시안) 분포를 사용하여 가중치 평균을 0으로 유도

#### 적절한 람다 값 선택하기
- 단순성과 학습 데이터 적합성 사이에 적절한 균형을 맞추는 것

람다 값이 높으면
  + 모델이 단순해지는 반면 데이터가 과소적합해질 위험
  + 학습이 제대로 되지 않음

람다 값이 낮으면
  + 모델이 복잡해지면서 데이터가 과적합해질 위험
  + 모델이 학습 데이터의 특수성을 많이 학습하게 되고, 새로운 데이터로 일반화하지 못함

#### L2 정규화화 학습률
- 공통점
  + 강력한 L2 정규화 값은 특성 가중치를 0에 가깝게 유도
  + 낮은 학습률(조기중단도 포함)도 특성 가중치를 0에 가깝게 유도
- 주의할 점
  + 람다와 학습률은 결과적으로 유사한 결과를 도출한다.
  + 따라서 람다와 학습률을 동시에 변경하면 혼동스러운 결과를 낳을 수 있다.
- 결론
  + 온라인 학습시 조기중단(모델이 완전히 수렴하기 전에 학습을 끝내는 것)이 많은데, 이 때 정규화의 효과와 혼동하지 않도록 반복횟수를 늘려서 조기 중단이 발생하지 않도록 한다.

## 플레이그라운드 실습: L2 정규화
### 정규화율을 0에서 0.3으로 증가시키면
- 테스트 손실이 대폭 감소한다. (중요! 테스트 손실이 결국 좋은 모델을 만들기 위한 판단 기준이 되기 때문)
- 테스트 손실과 학습 손실 사이의 델타 값이 대폭 감소합니다.
- 특성과 일부 특성 교차에 대한 가중치의 절대값이 낮으므로 모델 복잡도도 떨어집니다

## 이해도 확인
### L2 정규화
```
100개의 입력 특성이 있는 선형 모델에서
10개는 매우 유용하고, 90개는 유용하지 않다.
모든 특성이 -1과 1 사이의 값을 갖는다고 가정했을 때...
```
- L2 정규화는 많은 유용하지 않은 가중치를 정확히는 아니지만 0에 가깝게 유도한다!
- L2 정규화로 인해 모델이 일부 유용하지 않은 특성에 대해 적정 가중치를 학습하게 될 수 있다.

### L2 정규화와 상관 특성
```
밀접한 상관 관계있는 두 개의 특성은 서로 거의 동일하지만 
둘 중 하나의 특성에는 임의의 노이즈가 조금 포함되어 있다. 
L2 정규화를 사용해 이 모델을 학습한다면 이러한 두 특성에 대한 가중치는 어떻게 될까?
```
- L2 정규화는 두 가지 특성 중 하나만 모델에 포함한 경우의 대략 절반 수준인 대체로 동일한 가중치를 향하여 특성을 이끌어 간다. 
- 즉, 가중치에 큰 영향이 없다
