- [1-01. ML소개](1-01.Introduction-to-Machine-Learning)(3분)
- [1-02. ML문제로 표현하기](1-02.Framing.md)(15분)
- [1-03. ML문제로 전환하기](1-03.Descending-into-ML.md)(20분)
- [1-04. 손실 줄이기](1-04.Reducing-Loss.md)(60분)
- [1-05. TF 첫걸음](1-05.First-Steps-with-TensorFlow.md)(60분)
- [1-06. 일반화](1-06.Generalization.md)(15분)
- [1-07. 학습 및 평가세트](1-07.Training-and-Test-Sets.md)(25분)
- [1-08. 검증](1-08.Validation.md)(40분)
- [1-09. 표현](1-09.Representation.md)(65분)
- [1-10. 특성 교차](1-10.Feature-Crosses.md)(70분)
- [1-11. 정규화 단순성](1-11.Regularization-for-Simplicity.md)(40분)
- [1-12. 로지스틱 회귀](1-12.Logistic-Regression.md)(20분)
- [1-13. 분류](1-13.Classification.md)(90분)
- [1-14. 정규화 희소성](1-14.Regularization-for-Sparsity.md)(45분)
- [1-15. 신경망 소개](1-15.Introduction-to-Neural-Networks.md)(55분)
- [1-16. 신경망 학습](1-16.Training-Neural-Networks.md)(40분)
- [1-17. 다중 클래스 신경망](1-17.Multi-Class-Neural-Networks.md)(50분)
- [1-18. 임베딩](1-18.Embeddings.md)(80분)

# 1. ML 개념

## ML 소개
여기서 배운 내용을 활용하면 SW 엔지니어로서 세가지(+a)를 더 잘 할 수 있다.
1. 프로그래밍 시간을 줄일 수 있는 도구를 얻게 된다. 
  -  ex: 맞춤법 오류 수정하는 프로그램 작성시 사람vs머신러닝
2. 제품을 맞춤설정하여 특정 집단의 사용자에게 더 잘 맞는 제품을 제공할 수있다. 
  - ex: 철자 교정 도구를 100개 언어로 제작시 사람vs머신러닝
3. 프로그래머로서 수동으로 할 방법이 없어 보이는 문제를 해결할 수 있다. 
  - 알고리즘에게 무엇을 하라고 명령할 필요 없이 수많은 예를 보여주면 문제가 해결된다.
4. +a (철학적인 이유)
  - 문제에 관해 생각하는 방법을 바꿈
  - 논리적/수학적 사고 -> 불확실한 세계 관찰/통계적 사고
  - 문제에 대한 시야가 넓어지고 이전에 가지 못한 새 영역으로 나갈 수 있다.

## ML 문제로 표현하기

### 동영상
Supervising machine Framework
-  라벨(Label)
    + 지도 학습에서 학습을 위해 제공하는 것
    + 이메일 스팸 필터링이라면 label = {'spam', 'not spam'} 정도가 될 것
    + 예측하는 실제 항목으로써 선형회귀에서 `y` 변수
- 특성(feature)
    + 데이터를 설명하는 입력변수 `x = {x_1, x_2, ...}`
    + 이메일 스팸 필터링이라면 이메일에 포함된 단더, 이메일주소, 라우팅 정보, 헤더 정보 ... 가 될 수 있다.
- 모델
    + 예측을 하도록 해줌
    + (특성o, 라벨x) => 모델 => **라벨 예측(=추론)!**

### ML 용어

머신러닝이란?
- 입력을 결합하여 이전에 본 적이 없는 데이터를 적절히 예측하는 방법을 학습한다.

라벨
- 예측하는 항목
- 단순 선형회귀의 `y` 변수)

특성
- 입력변수
- 단순 선형회귀의 `x` 변수
- 특성은 1개 이상 사용하며, 복잡한 프로젝트일수록 많이 사용

예
- 데이터(x)의 인스턴스
- 라벨이 있는 예(특성o, 라벨o): 학습용
- 라벨이 있는 예(특성o, 라벨x): 예측용

모델
- 특성과 라벨의 관계를 정의한다.
- 학습
  + 모델을 만들거나 배우는 것
  + (특성o, 라벨o) 데이터로 학습시킴
- 추론
  + 학습된 모델을 라벨이 없는 예에 적용하는 것
  + (특성o, 라벨x) 데이터 => 모델 => 추론!

회귀와 분류
- 회귀 모델
  + 연속적인 값을 예측 (수치, 확률, ...)
- 분류 모델
  + 불연속적인 값을 예측 (스팸인지아닌지, 고양이/강아지 판단, ...)

### 이해도 확인
> 주어진 이메일이 '스팸' 인지 '스팸이 아닌지' 예측하기 위해 지도 머신러닝 모델을 개발한다고 합시다. 다음 중 참인 내용은 무엇일까요?
- 일부 라벨은 신뢰할 수 없을 수도 있습니다.(o)
- '스팸' 또는 '스팸 아님'으로 표시되지 않은 이메일은 라벨이 없는 예입니다. (o)
- 모델을 학습시키는 데는 라벨이 없는 예를 사용합니다.(x)
  + 라벨 있는 예로 학습시킨다.
- 제목 헤더의 단어는 라벨로 사용하기에 적절합니다.(x)
  + 특성: 제목 헤더의 단어, ...
  + 라벨: 스팸o/스팸x

> 한 온라인 신발가게에서 사용자에게 맞춤형 신발을 추천하는 지도 ML 모델을 만들려고 합니다. 즉 이 모델에서는 철수에게 특정 신발을 추천하고 영희에게는 다른 신발을 추천합니다. 다음 중 참인 내용은 무엇일까요?
- 사용자의 신발 설명 클릭수는 유용한 라벨입니다. (o)
  + 마음에 드는 것만 클릭해서 설명을 볼 것이므로
- 사용자가 아주 좋아하는 신발은 유용한 라벨입니다. (x)
  + 좋아한다는 것은 추상적임 => 관찰 불가능/수량화 불가
  + 추상적인 것을 관찰가능한 다른 측정학목으로 변경하여 라벨화
- 신발 크기는 유용한 특성입니다. (o)
  + 마음에 드는 신발인지 판단하는 기준이 된다.
- 신발의 아름다움은 유용한 특성입니다. (x)
  + 모호한 개념
  + 구체적이고 수량화 가능한 특성이 좋은 특성

## ML로 전환하기
### 선형회귀
```
y' = wx + b     : 1차원의 경우(1가지 특성에 의존)
y' = w_1x_1 + b + w_2x_2 + ... : 차원이 늘어나는 경우(여러가지 특성)
```
- y': 예측된 라벨(얻고자 하는 결과)
- b : 편향(y절편), w_0라고 하기도 한다.
- w_1: 특성1의 가중치
- x_1: 특성1(알려진 입력)

> 알려진 특성 입력하여 모델 만들고,<br>
> 알려지지 않은 새로운 특성에서 라벨 추론

### 학습 및 손실
> 모델을 학습시킨다 = 라벨이 있는 데이터로부터 올바를 가중치(w)와 편향값(b)을 결정한다.

> 경험적 위험 최소화: 손실을 최소화하는 모델을 찾아봄으로써 모델을 만들어 낸다.

즉, 손실이 가장 작은 모델이 가장 좋은 모델이다!

#### 제곱손실(L2 손실)
```
= (observation - prediction(x))^2
= (y-y')^2
```
- 참고로 L1 손실은 `|  y - y' |`

#### 평균제곱오차(MSE, Mean Squared Error)
- L2 손실을 평균낸 것
```
MSE = 1/N * sum( (y-prediction(x))^2 )
```

### 손실 줄이기
#### Overview
- 손실함수는 y=x^2꼴
- 손실함수의 경사가 작아지는 방향으로 다음 모델을 업데이트하는 과정을 반복
- 경사가 낮아지는 방향으로 지나면 극소값을 지남
- 얼마나 많이 경사가 낮아지는 방향으로 이동해야 하는가?
  + 학습률이 크면 많이 이동
  + 학습률이 작으면 적게 이동
- 초기값이 중요한 이유
  + 극소값이 하나면 좋은데 대부분의 경우 극소값이 하나가 아님
  + 특히 딥러닝의 경우에는 계란판 모양임

#### 반복방식
- `y = b + w1x1`
- L2 손실[= (y-y') 제곱의 평균]을 최소화하는 방향으로 이동하도록 b, w1를 업데이트한다.
- 이 때 L2를 계속 구하면서 전체 손실이 변하지 않거나 매우 느리게 변할 때까지 반복하면 되는데, 이 경우를 모델이 수렴했다고 한다.

### 경사하강법
- 손실함수를 최소화하는 w_i를 찾도록 하는 방법
- 시작점(w,b)에서의 미분값(기울기)을 구하여 그 반대방향으로 이동함
  + 기울기(+) => 그 반대방향(-)으로 이동
  + 기울기(-) => 그 반대방향(+)으로 이동
### 학습률
- 경사하강법에서 다음 지점을 결정하는 방법
  + 다음지점 = 현재지점 + (-)x기울기x학습률
- 학습률(=보폭)
  + 너무 작으면 학습시간이 너무 오래 걸림
  + 너무 크면 최저점을 못찾을 수도 있음
- 골디락스 학습률
  + 골디락스: 너무 크지도 너무 작지도 않은 적절한 상태
  + 골디락스 학습률을 구하기 위해서 손실함수의 기울기가 크면 큰 학습률을, 손실함수의 기울기가 작으면 작은 학습률을 설정

### 학습률 최적화
- 실습 1. 학습률 0.1인 경우 손실 최저점에 도달할때까지 몇단계?
  + 0.1: 81단계
- 실습 2. 학습률 1인 경우 손실 최저점에 도달할때까지 몇단계?
  + 1.0: 6단계
- 실습 3. 학습률 4인 경우 손실 최저점에 도달할때까지 몇단계?
  + 발산한다
  + 경사하강법으로 손실 최저점에 도달할 수 없습니다. 학습률을 바꿔서 다시 시도해 보세요.
- 선택과제: 경사하강법에서 최저점에 도달하는 단계수를 최소화하는 골디락스 학습률?
  + 0.5: 14회
  + 0.6: 12회
  + 0.7: 10회
  + 0.8: 8회
  + 0.9: 7회
  + 1.0: 6회
  + 1.1: 5회
  + 1.2: 4회
  + 1.3: 4회
  + 1.4: 3회
  + 1.5: 2회
  + 1.6: 1회 => `골디락스 학습률!`
  + 1.7: 2회
  + 1.8: 3회
  + 1.9: 3회

### 확률적 경사하강법
- 배치: 한 반복에서 기울기를 계산하는데 사용하는 예의 총 개수
- 반복이 여러번 되는데 매번 기울기 계산을 위해 무작위로 선택된 적은 데이터셋으로 기울기 계산
- 확률적 경사하강법(SGD)
  + 반복당 하나의 예(배치크기 1)만을 사용
  + 반복이 여러번일 경우 효과 있음
  + 노이즈가 심하게 나타남
- 미니 배치 확률적 경사하강법(미니 배치 SGD)
  + 전체 배치 반복과 SGD 간의 정충안
  + 무작위로 10개~1000개 사이의 예로 구성
  + SGD보다 노이즈 적고, 전체 배치보다 효율적

### 플레이그라운드 실습
- 점
  + 파란색 점: 스팸메일x
  + 주황색 점: 스팸메일o
- 배경
  + 모델이 예측하는 라벨
  + 같은 점에 같은 배경이 있으면 올바른 것
  + 배경색이 진할수록 예측 확률이 더 높음

#### 작업 1. (높은) 학습률 실습
- 학습률 3: 학습 손실 = 0.3정도
#### 작업 2. (낮은) 학습률 실습
- 학습률 1: 학습 손실 = 0.2 정도
- 학습률 0.3: 학습 손실 = 0.18 정도
- 학습률 0.1: 학습 손실 = 0.2 정도

### 이해도 확인: 배치크기
다음 중 대량의 데이터 세트에서 경사하강법을 수행할 때 더 효율적인 배치 크기는 어느 것일까요?
- 소규모 배치 또는 예가 하나뿐인 배치(SGD)
  + 데이터세트가 대량이라 중복이 많고 시간이 오래 걸린다.
  + 소규모 배치로도 정확도는 비슷하고 효율적인 기울기 계산이 가능하다.

## TF 첫걸음
### 도구(Toolkit)

#### Toolkit 계층구조
- 높은 수준의 객체지향 API
  + TF Estimators: 
- 일반 모델 구성요소용 재사용가능한 라이브러리
  + ft.layers, tf.losses, tf.metrics: 
- TensorFlow
  + TF Python: c++ 커널을 래핑하는 오퍼레이션 제공
  + TF c++
- 하드웨어 CPU / GPU / TPU

#### TF 구성요소
1. 그래프 프로토콜 버퍼
  + 프로토콜 버퍼: 구조화된 데이터를 직렬화하는데 사용하는 메커니즘. language-neutral, platform-neutral
2. 분산된 그래프를 실행하는 런타임

#### tf.estimator API
- 추상화가 많이 되어있어 코딩 라인 수가 줄어든다.

### 실습
#### 1. [Pandas 간단 소개](https://colab.research.google.com/notebooks/mlcc/intro_to_pandas.ipynb?hl=ko)
  - pd.DataFrame: 이름 지정된 열이 포함된 관계형 데이터 테이블
  - pd.Series: 하나의 열. DataFrame에는 하나 이상의 Series와 각 Series의 이름이 포함된다.
  - pd.read_csv: csv파일에서 읽어오기
  - Dataframe.describe(): dataframe의 내용 표로 보여줌(Dataframe.head(): 처음 몇개만 보여줌)
  - Dataframe.hist('title'): dataframe의 히스토그램을 보여줌('': 표 제목)
  - Python dict/list로 Dataframe 접근 가능(일종의 배열 iterable)
  ```
  cities = pd.DataFrame({ 'City name': city_names, 'Population': population })
  print type(cities['City name'])
  cities['City name'] // City name이라는 열의 전체 데이터 (js의 object랑 비슷한듯)
  <결과>
    0    San Francisco
    1         San Jose
    2       Sacramento
  ```
  - python 기본 산술연산을 Series에 적용
  ```
  population / 1000
  <결과>
  전체 series의 데이터가 다 1000으로 나누어짐
  ```
  - 복잡한 열 변환은 Series.apply 활용
    + lambda 함수 허용(map함수와 유사)
  - Dataframes 수정: Dataframe에 새로운 값을 할당
  - index
    + Dataframe, series는 행에 index가 있음
    + index method로 start, stop, step 속성 확인 가능
    + reindex method[index, index, ...]로 재정렬 가능

실습 #1
```
도시 이름은 성인의 이름을 본따서 지었다.
도시 면적이 130제곱킬로미터보다 넓다.
cities['myCondition'] = (cities['Area square miles'] > 130) & cities['City name'].apply(lambda name: name.startswith('San'))

cities
```

실습 #2
```
reindex method에는 index의 start와 stop 벗어나는 값도 허용
벗어난 index는 NaN으로 표시된다.
```

#### 2. [텐서플로우 첫걸음](https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?hl=ko)

#### TF 코드의 전반적인 흐름
  1. 설정
    - 필요한 라이브러리 로드
      + numpy, tensorflow, pandas, metplotlib, ...
    - 데이터세트 로드
      + pd.read_csv("source")
  2. 데이터 조사
    - 데이터를 미리 확인
      + Dataframe.describe()
  3. 모델 생성
    1. 특성 정의 및 특성 열 구성(total_rooms: 방의 개수)
    2. 타겟 정의(집값 중간값: median_house_value)
    3. LinearRegressor 구성(선형회귀모델)
    4. 입력 함수 정의(한번에 몇개씩 넣을지, 섞을지, 반복을 얼마나할지 등 지정)
    5. 모델 학습(train methods)
    6. 모델 평가(테스트셋으로 오차(정확도) 확인, 샘플추출하여 그래프 확인)
  4. 초매개변수 조정(learning rate, step, batch size, input feature 변경, ...)

#### 3. [합성 특성과 이상점](https://colab.research.google.com/notebooks/mlcc/synthetic_features_and_outliers.ipynb?hl=ko)

데이터 학습의 정확도 향상을 위한 전처리 과정

합성 특성
- 서로 다른 두 특성을 적절히 조합하여 새로운 특성을 만든 것

이상점 식별
- 예측과 목표값을 그래프로 확인해본다.(Pyplot.scatter())

이상점 삭제
- 입력 데이터에서 이상점을 식별 및 삭제하여 모델의 효율성을 개선한다.

#### 머신러닝 단기집중과정 실습에서 자주 사용되는 초매개변수
- 초매개변수(hyperparameter): 내가 조절해야하는 변수. ex) 학습률
- steps: 총 학습 반복 횟수. 배치의 반복 수
- batch size: 하나의 단계에서의 예시의 수. ex) SGD에서 1 
- 학습된 예의 총 수 = batch x steps

#### 머신러닝 단기집중과정 실습에서 자주 사용되는 변수
- periods: 보고하는 기간 설정

## 일반화
### 과적합의 위험
과적합 모델은 학습하는 동안 손실이 적지만 새 데이터를 잘 예측하지 못한다.

머신러닝의 근본적인 과제는 데이터 적합도를 유지하는 동시에 최대한 단순화하는 것이다. (필요 이상으로 복잡한 모델을 만들면 과적합 발생)

Occam의 면도날 법칙
- 14세기의 수도사이자 철학자인 William of Occam
- 과학자는 복잡한 것보다 간단한 공식이나 이론을 선택해야 한다고 하였음
- => ML 모델이 덜 복잡할수록 샘플의 특성 때문이 아니어도 좋은 경험적 결과를 얻을 가능성이 높다!

일반화 한계(Generalization Bounds)
- Occam의 면도날 법칙을 통계적 학습이론 및 컴퓨터 학습 이론 분야에서 공식화한 것
- 모델의 복잡성, 학습 데이터에 대한 모델의 성능을 기반으로 새 데이터에 맞게 모델이 일반화되는 정도를 나타낸다.

일반화 판단
- 학습세트와 테스트 세트로 나누어 판단

### ML 세부사항
일반화에서 다음 세가지를 가정한다.
1. i.i.d
  - 분포에서 독립적이고, 동일하게 예를 추출한다고 가정
2. stationary
  - 데이터 세트 내에서 분포가 달라지지 않는다.
3. 같은 분포를 따르는 부분에서 예를 추출한다.


## 학습 및 평가 세트

### 학습세트와 평가세트
- 학습세트: 모델을 학습시키기 위한 데이터 세트의 일부분
- 평가세트: 모델을 테스트하기 위한 데이터 세트의 일부분

### 평가세트의 조건
1. 통계적으로 유의미한 결과를 도출할 만큼 커야 한다.
2. 데이터 세트를 전체적으로 나타내야 한다. 즉, 평가 세트가 학습 세트와 같은 특징을 가지도록 선별해야 함

### 평가시 주의할 점
- 학습세트와 평가세트를 구분한다.
- 테스트 데이터로 학습시키면 실제 성능과 달리 정확도수치만 높아질 수 있다.
- 반대로 정확도가 너무 높다면 테스트 세트가 학습세트로 유출되었는지 의심해볼 것

### 실습
작업1. 학습/테스트 데이터 비율: 50%, 학습률 3
- 테스트 손실: 0.345
- 학습 손실: 0.280
- 차이: 0.065
작업2-1: 학습/테스트 데이터 비율: 50%, 학습률 1
- 테스트 손실: 0.335
- 학습 손실: 0.280
- 차이: 0.055
작업2-2: 학습/테스트 데이터 비율: 50%, 학습률 0.1
- 테스트 손실: 0.298
- 학습 손실: 0.271
- 차이: 0.027
```
=> 학습률 낮을수록 테스트손실, 학습손실 차이가 줄어들었음
=> 배치크기 늘릴수록 테스트 손실, 학습 손실 모두 줄어들었음
```

선택적 작업3: 학습/테스트 데이터 비율 조절
3-1. 학습/테스트 데이터 비율: 10%, 학습률 3
- 테스트 손실: 0.291
- 학습 손실: 0.120
- 차이: `0.171`
3-1. 학습/테스트 데이터 비율: 30%, 학습률 3
- 테스트 손실: 0.233
- 학습 손실: 0.147
- 차이: `0.086`
3-2. 학습/테스트 데이터 비율: 50%, 학습률 3
- 테스트 손실: 0.345
- 학습 손실: 0.280
- 차이: `0.065`
3-3. 학습/테스트 데이터 비율: 70%, 학습률 3
- 테스트 손실: 0.240
- 학습 손실: 0.206
- 차이: `0.036`
3-1. 학습/테스트 데이터 비율: 90%, 학습률 3
- 테스트 손실: 0.200
- 학습 손실: 0.231
- 차이: `0.031`

==> 학습/테스트 데이터 비율 높아질수록 차이가 작아짐
==> 배치 크기 늘리면 테스트 손실이 학습 손실보다 낮아짐

