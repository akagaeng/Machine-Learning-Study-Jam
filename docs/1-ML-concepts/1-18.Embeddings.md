# 임베딩 (Embedding)

> 임베딩은 고차원 벡터의 변환을 통해 생성할 수 있는 상대적인 저차원 공간을 가리킵니다. 임베딩을 사용하면 단어를 나타내는 희소 벡터와 같이 커다란 입력값에 대해 머신러닝을 더 쉽게 수행할 수 있습니다. 임베딩이 잘 동작하는 경우 의미가 유사한 입력값들을 임베딩 공간 안에 서로 근접하게 위치시켜 입력값의 특정 의미를 포착합니다. 임베딩은 모델과 관계없이 학습과 재사용이 가능합니다.

협업 필터링에서 필요한 경우
- 입력: 사용자 50만명이 선택한 영화 100만편
- 작업: 사용자에게 영화 추천

이 문제를 해결하려면 어떤 영화가 서로 비슷한지 파악해야 한다.

1. 유사성별로 영화 정리(1차원)

- 애니메이션 ---> 성인영화
```
슈렉 - 인크레더블 - 벨빌의 세 쌍둥이 - 해리포터 - 스타워즈 - 세 가지 색: 블루 - 다크나이트 라이즈 - 메멘토
```
- 1차원으로 표현시 사람들이 어떤 요소들을 좋아하는지 복잡하게 파악하기는 어렵다.

2. 유사성별로 영화 정리(2차원)
- x축: 어린이 ~ 성인
- y축: 예술영화 ~ 블록버스터
- 파악하고싶은 요소를 2가지(x축,y축) 고려할 수 있다.
- 슈렉(-1.0, 0.95) 블루(0.65, -0.2)로 표현할 수 있다.
- 추천해줄 영화를 선정할 때 유사성이 있을수록 거리가 가깝게 나타나므로 그 영화를 추천해줄 수 있음

### d차원 임베딩
- 영화에 대한 사용자의 관심분야를 대략 d개의 측면에서 설명할 수 있다고 가정
- 각각의 영화는 차원 d의 값이 해당 측면에 대한 각 영화의 일치도를 나타내는 d차원의 지점이 된다.
- 임베딩은 데이터를 통해 학습할 수 있다.

### 심층망에서 임베딩 학습
- 임베딩 레이어는 차원당 단위 하나를 갖는 히든 레이어에 불과하므로 별도의 학습 과정이 필요하지 않다.
- 지도 정보(예: 사용자가 동일한 영화 2개를 시청함)를 통해 원하는 작업에 맞게 학습된 임베딩을 조정한다.
- 히든 단위는 최종 목표를 최적화하도록 d차원 공간에서 항목을 정리하는 방법을 직관적으로 발견한다.

### 입력 표현
```
[슈렉, 인크레더블, 벨빌의 세 쌍둥이, 해리포터, 스타워즈, 세 가지 색: 블루, 다크나이트 라이즈, 메멘토]

따라서 0번은 슈렉, 1번은 인크레더블, ...
```

어떤 사용자 x가 본 영화를 다음과 같이 표현할 수 있다.
```
(0, 1, 4)

이는 즉 슈렉, 인크레더블, 스타워즈를 의미한다.
```

### 임베딩 차원 개수 선택
- 고차원 임베딩은 입력값 간의 관계를 더 정확하게 표현할 수 있다.
- 하지만 차원이 많아지면 과적합 확률이 높아져 학습속도가 느려진다.
- 경험적 법칙은 시작점으로는 좋지만 유효성 확인 데이터를 사용하여 조정하여야 한다.
  + 경험적 법칙: dimensions ~= possible values^(1/4)

## 임베딩: 협업 필터링에서 필요한 경우(협업필터링의 동기)
