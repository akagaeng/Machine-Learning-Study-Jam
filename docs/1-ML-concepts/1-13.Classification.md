# 분류 (Classification)

## 분류 임계값 (Classification Threshold)
로지스틱 회귀 모델에서 이메일에 관해 0.9995가 반환되면?
- 스팸일 가능성이 매우 높은 메일

로지스틱 회귀 모형에서 예측 점수가 0.0003점이면?
- 이 이메일은 스팸이 아닐 가능성이 높음

예측 점수가 0.6점인 이메일은?
- 애매함

로지스틱 회귀 값을 이진 카테고리에 매핑하려면 분류 임계값(결정 임계값이라고도 함)을 정의해야 한다. 

- 임계값보다 높은 값: '스팸'
- 임계값보다 낮은 값: '스팸 아님'

```
분류 임계값은 항상 0.5여야 한다고 생각하기 쉽지만, 임계값은 문제에 따라 달라지므로 값을 조정해야 한다.
```

## 분류 참(true) vs 허위(false), 양성(positive) vs 음성(negative)

```
이솝우화: 양치기 소년에서
양치기 소년이 늑대다! 라고 소리쳤으니 사람들은 소년이 거짓말을 한다고 생각해서 집에서 나오지 않았다.
```

### Positive vs Negative
- 늑대다!: 양성 클래스(positive)
- 늑대가 없다: 네거티브 클래스(negative)

### True vs False
- true: 소년이 참을 이야기 했다.
- false: 소년이 거짓을 이야기 했다.

### 늑대 예측 모델에서 발생할 수 있는 4가지 결과
- 참 양성(TP, true positive)
  + 소년: 늑대다! `양성, positive`
  + 현실: 늑대가 있었다. `참, true`
- 허위 양성(FP, false positive)
  + 소년: 늑대다! `양성, positive`
  + 현실: 늑대가 없었다. `거짓, false`
- 참 음성(TN, true negative)
  + 소년: 늑대가 없다! `음성, negative`
  + 현실: 늑대가 없다. `참, true`
- 허위 음성(FN, false negative)
  + 소년: 늑대가 없다! `음성, negative`
  + 현실: 늑대가 있었다. `거짓, false`

### 정확한 예측 vs 잘못된 예측
- 정확한 예측
  + 참 양성 `true positive`
  + 거짓 음성 `false negative`
- 잘못된 예측
  + 거짓 양성 `false positive`
  + 참 음성 `true negative`

## 정확성

정확성은 분류 모델 평가를 위한 측정항목 중 하나로써 모델의 예측이 얼마나 정확한가를 보여준다. 정확성을 구하는 식은 다음과 같다.

```
정확성 = 정확한 예측수 / 총 예측수
```

```
정확성 = (TP + TN) / (TP + TN + FP + FN)
```

### 양성종양(Positive), 악성종양(Negative)인 경우
- TP
  + 실제: 악성종양(Positive)
  + ML모델 예측: 악성종양(Positive)
  + TP 결과: 1개
- FN
  + 실제: 악성종양(Positive)
  + ML모델 예측: 양성종양(Negative)
  + 8개
- FP
  + 실제: 양성종양(Negative)
  + ML모델 예측: 악성종양(Positive)
  + 1개
- TN
  + 실제: 양성종양(Negative)
  + ML모델 예측: 양성종양(Negative)
  + 90개

악성 종양(Positive)을 제대로 예측한 경우
```
1/9 = TP / (TP + FN)

```

양성 종양(Negative)을 제대로 예측
```
90/91 = TN / (TN + FP)
```

> 클래스 불균형 데이터 세트(class-imbalanced data set, 두 클래스 라벨 즉, Positive와 Negative가 99:1과 같이 서로 크게 다른 빈도를 보임)를 사용하면 양성 라벨수와 음성 라벨수가 상당히 다르므로 정확성만으로는 모든 것을 평가할 수 없다!


## 정밀도와 재현율(Precision and Recall)

### 정밀도(Precision)

`양성(Positive)으로 "식별된(예측한) 사례" 중에서 실제로 양성(Positive)이었던 사례의 비율은?`

```
정밀도 = TP / (TP + FP)
```
- 즉, 정밀도는 P(Positive)로 예측한 것 중에서 실제 예측이 일치(True Positive)하는 것의 비율이다.

### 재현율(Recall)

`실제 양성(Positive) 중에서 정확히 양성(Positive)이라고 식별된(예측한) 사례의 비율은?`
- 실제 양성인 케이스: TP, FN 

```
재현율 = TP / (TP + FN)
```

- 즉, 재현율은 실제 결과가 P(Positive)인 것 중에서 실제 예측이 일치(True Positive)하는 것의 비율이다.

### 정밀도 및 재현율

- 모델의 효과를 완전히 평가하기 위해서는 `정밀도와 재현율을 모두 검사`해야 한다.
- 그런데 정밀도와 재현율은 서로 `상충`하는 경우가 많다.

### 분류 임계값과 정밀도/재현율
- 분류 임계값(Classification Threshold)이 변경되면 정밀도와 재현율이 변한다.
- 분류 임계값보다 높은 것은 positive로, 분류 임계값보다 낮은 것은 negative로 판단한다.

### 분류 임계값이 높아지면
- 정밀도: 올라감(`FP가 감소`)
- 재현율: 내려감(`FN가 증가`)

### 분류 임계값이 낮아지면
- 정밀도: 내려감(`FP가 증가`)
- 재현율: 올라감(`FN가 감소`)

### F1 점수
- 정밀도와 재현율을 모두 반영하는 측정방법이 있으면 둘간의 상충관계를 다 반영할 수 있다.

```
F1 = 2 * (precision * recall) / (precision + recall)
```


## 분류: 이해 내용(정확성, 정밀도, 재현율) 확인
### 정확성
> 다음 중 어떤 시나리오에서 높은 정확성 값을 통해 ML 모델이 제대로 실행되고 있음을 알 수 있나요?


> 룰렛 게임에서 회전하는 룰렛 휠에 공이 떨어지면 결국 슬롯 38개 중 하나로 들어갑니다. ML 모델은 시각적 특징(공의 회전, 공이 떨어졌을 때 룰렛 휠의 위치, 룰렛 휠 위 공의 높이)을 사용하여 공이 들어갈 슬롯을 4%의 정확성으로 예측할 수 있습니다.

이 ML 모델은 운보다는 훨씬 정확하게 예측합니다. 어림짐작을 하면 38번 중 1번은 정확하므로 2.6%의 정확성을 나타냅니다. 모델의 정확성은 4%에 '불과'하지만 성공의 장점이 실패의 단점보다 훨씬 큽니다.

### 정밀도
> 이메일을 '스팸'과 '스팸 아님', 두 카테고리로 구분하는 분류 모델을 가정해 보겠습니다. 분류 임계값을 올리면 정밀도는 어떻게 될까요?

아마도 증가할 것입니다.
- 분류 임계값을 높이면 FP가 낮아져서 정밀도가 높아진다.


### 재현율
> 이메일을 '스팸'과 '스팸 아님', 두 카테고리로 구분하는 분류 모델을 가정해 보겠습니다. 분류 임계값을 올리면 재현율은 어떻게 될까요?

항상 감소하거나 그대로 유지됩니다.
- 분류 임계값을 높이면 FN가 높아져서 재현율이 낮아진다.

### 정밀도와 재현율
> 각각 동일한 데이터세트를 평가하는 두 모델, A와 B가 있다고 가정해 보겠습니다. 다음 설명 중 참인 것은?

모델 A의 정밀도와 재현율이 모두 모델 B보다 높은 경우, 모델 A가 더 나을 수 있습니다.
- 일반적으로 정밀도와 재현율 *모두* 다른 모델을 능가하는 모델이 더 나을 가능성이 높습니다. 



## ROC 및 AUC
- ROC: Receiver Operating Characteristic curve (수신자 조작 특성)
- AUC: Area under curve (ROC 곡선 아래 영역)

### ROC(수신자 조작 특성 곡선)
- 모든 분류 임계값에서 분류 모델의 성능을 보여주는 그래프
- 매개변수
  + 참 양성 비율(TPR, True Positive Ratio)
  + 허위 양성 비율(FPR, False Positive Ratio)

```
TPR = TP / (TP + FN)
```

```
FPR = FP / (FP + TN)
```

### AUC (ROC 곡선 아래 영역)
- 가능한 모든 분류 임계값에서 성능의 집계 측정값을 제공
- 모델이 임의의 양성(positive) 예제를 임의의 음성(negative) 예제보다 더 높게 평가할 확률
- 값의 범위는 0~1
  + 예측이 100% 정확: AUC=1.0
  + 예측이 100% 잘못: AUC=0.0
  
AUC의 장단점
- 장점
  + 척도 불변: 절대값이 아니라, 예측이 얼마나 잘 평가되는지 측정한다.
  + 분류 임계값 불변: 어떤 임계값이 선택되었는지와 상관없이 모델의 예측 품질을 측정한다.
- 단점
  + 척도 불변이 항상 이상적인 것이 아님
  + 분류 임계값 불변이 항상 이상적인 것은 아님

## 이해도 확인(ROC 및 AUC)

### ROC 및 AUC

> 다음 ROC 곡선 중에서 0.5보다 큰 AUC 값을 산출하는 곡선은 무엇일까요?

- x축이 FP 비율, y축이 TP 비율인 그래프(ROC)에서 넓이가 0.5 이상인 것을 찾으면 된다.

### AUC 및 조정 예측

> 주어진 모델에서 모든 예측에 2.0을 곱하면(예를 들어 모델이 0.4를 예측하는 경우 2.0을 곱하여 0.8이라는 예측을 산출) AUC로 측정한 모델의 예측 성능이 어떻게 바뀔까요?

- 바뀌지 않습니다. AUC는 상대적인 예측 점수만 고려합니다.
- 그러나 제곱 오차, 로그 손실, 예측 편향(추후에 설명) 등 다른 측정항목은 변한다.

